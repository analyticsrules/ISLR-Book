


###CHapter 6


################   BEST SUBSET SELECTION        ###################

library(ISLR)
attach(Hitters)
str(Hitters)

dim(Hitters) # 20 variables; 19 independent and one dependent

#THere are 59 missing values in salary variable
sum(is.na(Hitters$Salary))

#Removing all the rows which have missing values
Hitters = na.omit(Hitters)


#regsubsets fn does the subset selection which is part of leaps library. Summary shows the results
library(leaps)
RegSub = regsubsets(Salary ~., data = Hitters)

#regsubsets identifies the best model using RSS. An asterisk indicates that a given variable is included in the corresponding
#model.By default, regsubsets only reports results up to the best eight-variable model.
summary(RegSub)

#But the nvmax() option can be used in order to return as many variables as are desired. Here we fit up to a 19-variable model.
RegSub1 = regsubsets(Salary ~., data=Hitters, nvmax=19)


RegSub1.Summ = summary(RegSub1)
names(RegSub1.Summ) #As we see, summary gives rss, adjsuted r-squared, Cp, BUC etc. We can examine these to select best model


#We see that r-Squared for including only one var is 32.14% while for all variables, it is 54.6%
RegFit.Summ$rsq


#Drawig the graph of RSS and Adjusted R-squared

#Clik on the brush in plot bar of RStudio if plot is showing error
#regsubsets() function has a built-in plot() command which can be used to display the selected
#variables for the best model with given no. of predictors, on the basis of various error parameters
plot(RegSub1, scale="r2") #Here each black square shows that the particular variable is selected in model
plot(RegSub1, scale="adjr2")
plot(RegSub1, scale="Cp")
plot(RegSub1, scale="bic")



#Several models in BIC plot have BIC values of -150. it has six variables. We can check the coeffiecints 
# 0f this model. This is sixth model out of the 19 we made.
coef(RegSub1, 6)



###############   FORWARD AND BACKWARD STEPWISE SELECTION    #################

#We can also do forward & backward stepwise using regsubsets() fn by giving method="forward/backward"

#FOrward stepwise selection methods. 1st six model of this method are same as best subset
Reg.fwd = regsubsets(Salary ~ ., data=Hitters, nvmax = 19, method = "forward")
summary(Reg.fwd)

#Backward Stepwise Selection Method
Reg.bwd = regsubsets(Salary ~ ., data=Hitters, nvmax = 19, method = "backward")
summary(Reg.bwd)

#However 7th model for each are quite different
coef(RegSub1, 7)
coef(Reg.fwd, 7)
coef(Reg.bwd, 7)




#############################################################################################
#####   CHOOSING AMONGST MODELS USING VALIDATION APPROACH & CROSS-VALIDATION        ##########
##############################################################################################

library(ISLR)
attach(Hitters)
sum(is.na(Hitters$Salary))
Hitters = na.omit(Hitters) #Removing all the rows which have missing values


train=sample (c(TRUE ,FALSE), nrow(Hitters ),rep=TRUE)
test =(! train ) #Dividing data randomly into training & test set
library(leaps)
regfit.best = regsubsets (Salary∼.,data=Hitters [train ,], nvmax =19) #Making model on training set
names(regfit.best)

test.mat = model.matrix(Salary∼.,data=Hitters [test ,]) #Making matrix of test data


#Now we run a loop, and for each size i, we matrix() extract the coefficients from regfit.best for the best model of that size,
#multiply them into the appropriate columns of the test model matrix to form the predictions, and compute the test MSE.
val.errors =rep(NA ,19)
 for(i in 1:19){
  coefi = coef(regfit.best ,id=i)
  pred=test.mat[,names(coefi)]%*% coefi
  val.errors [i]= mean(( Hitters$Salary[test]-pred)^2)
}

val.errors #Printing the MSE error tersms of all the 19 models

which.min(val.errors) #model that has 10 variable has minimum MSE ; hence it;s the best modek
coef(regfit.best, 10) #Coefficient of the model that has lowest MSE. it has 10 variables

#Now that we know 10-variable model is the best one on training set, we need to perform best 
#subset selection on full data and figure out the 10-variblae model
regfit.best1= regsubsets(Salary∼.,data=Hitters ,nvmax =19)
coef(regfit .best1 ,10)


#In fact, we see that the best ten-variable model on the full data set has a different set of 
#variables than the best ten-variable model on the training set.
