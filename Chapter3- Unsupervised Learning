
########################       PCA- Unsupervised Learning     ###################################


attach(USArrests)
states = USArrests

names(states)
head(states)
tail(states)
max(states$Assault)
which.max(states$Assault)
states$Assault[33]
states[33,]


# apply() func allows us to apply a function, mean() to each row or column of the data set. The second input here denotes whether we 
# wish to compute the mean of the rows, 1,or the columns, 2.# Here we see that all 4 variables have vastly diff mean values
apply(states , 2, mean)

#Checking the variance of all the 4 columns. Variables have vastly diff variances
apply(states , 2, var)

# UrbanPop is the percentage of population that lives in urban areas.


#Performing PCA. We're also scaling all variables because diff variables are measured on diff scales. It will make all variables having
# SD of 1.For eg. UrbanPop is %ge while Rape is rape cases for 100k population. prcomp is used for Principal component analysis
PCA1 = prcomp(states , scale =TRUE)

# prcomp has a number of useful quantities
names(PCA1)


# The center and scale components correspond to the means and standard deviations of the variables that were used for scaling prior
# to implementing PCA.
PCA1$center
PCA1$scale

# The rotation matrix provides the principal component loadings; each column of PCA1$rotation contains the corresponding principal 
# component loading vector.
PCA1$rotation

# X has principal component score corresponding to each column and row
edit(PCA1$x)
dim(PCA1$x)

#We can plot the 1st two component loadings as follows. The scale=0 argument to biplot() ensures that the arrows are scaled to 
# represent the loadings;
biplot(PCA1 , scale =0)

#Standard deviation for all the variables
PCA1$sdev

# Variance for the variables. It would be square of SD
var1 = PCA1$sdev^2
var1

# To compute the proportion of variance explained by each principal component, we simply divide the variance explained by each principal
# component by the total variance explained by all four principal components:
pve = var1/sum(var1)
pve

# We see that the first principal component explains 62.0% of the variance in the data,
# the next principal component explains 24.7% of the variance, and so forth.


#We can plot the PVE explained by each component, as well as the cumulative PVE, as follows
plot(pve , xlab="Principal Comp", ylab= "Proport of Variance Explained", ylim = c(0,1) ,type="b")

plot(cumsum (pve ), xlab=" Principal Component ", ylab ="Cumulative Proportion of Variance Explained ", ylim=c(0,1) ,type="b")

#Here cumsum() gives the cumulative sum of numerical vectors
a=c(1,2,8,-3)
cumsum(a)  #Ans would be 1, 3, 11, 8



####################################################################################################################



